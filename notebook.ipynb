{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Description\n",
    "\n",
    "## awards_players\n",
    "\n",
    "- playerId\n",
    "- award (should standardize and abreviate)\n",
    "- Lg ID (remove)\n",
    "- year\n",
    "\n",
    "## coaches\n",
    "\n",
    "- lgId (remove)\n",
    "- Stint (timeperiod coach was at the team) (use to convert years)\n",
    "- Post_wins e Post_loses (playoff wins, irrelevant, remove)\n",
    "  \n",
    "## players_teams\n",
    "\n",
    "- Stint (timeperiod player was in the team)\n",
    "- lgId (remove)\n",
    "- GP (games played)\n",
    "- GS (game started)\n",
    "- ORebounds (offensive rebounds)\n",
    "- DRebounds (defensive rebounds)\n",
    "- rebounds (total) (check sum of previous 2)\n",
    "- turnovers (negative stat)\n",
    "- PF (Personal Fouls)\n",
    "- Fg Attempted (field goals attempted)\n",
    "- Fg Made (maybe change to ratio)\n",
    "- Ft (free throws)\n",
    "- Dq (desqualify)\n",
    "- Post ... (maybe ignore)\n",
    "\n",
    "## Players\n",
    "\n",
    "- POS (postion, has missing value) (Center, Forward-Center, Guard, Forward-Guard) (check if multiple positions over time)\n",
    "- firstseason e lastseason (remove)\n",
    "- height (missing values) (check if same units)\n",
    "- college (some missing values, some none)\n",
    "- death date (ignore dead players)\n",
    "\n",
    "## series and teams post\n",
    "- ignore files, reffering to the season after playoffs qualification  \n",
    "\n",
    "## teams\n",
    "\n",
    "- TmId (team Id), Franch ID (Franchise Id) (maybe irrelevant, maybe not)\n",
    "- DivId (remove, all empty)\n",
    "- Rank (maybe seed)\n",
    "- Seeded (remove)\n",
    "- **Playoff** (N, Y) to predict next\n",
    "- first round, semis, finals (change to one column that has numbers that relate to when they got eliminated) (label0-no playoffs, label1-loss on first round, label2-loss on semis, label3-loss on finals, label4-no losses)\n",
    "- Name (already have ID, may not be necessary)\n",
    "- O_fgm (offensive field goals made)\n",
    "- O_fga (offensive field goals attempted)\n",
    "- Tm ORB, Tm DRB, Tm TRB ,Oppmt ORS, Oppmt DRB, Oppmt TRB (all 0, remove)\n",
    "- GP (all teams play all games, maybe remove column)\n",
    "- Win Loss -> create ratio\n",
    "- Conf W L (maybe irrelevent)\n",
    "- Attend (number of spectators, maybe irrelevant)\n",
    "- Arena (remove)\n",
    "\n",
    "\n",
    "# Developments\n",
    "\n",
    "## players_teams\n",
    "\n",
    "(All this was changed via python)\n",
    "- Got per games for main statistical categories (Points, Assists, Rebounds (Off and Def), Steals, Blocks, Turnovers, Personal Fouls)\n",
    "- Got percentages for main shots (Field Goals, Free Throws, Three Pointers)\n",
    "- Removed League ID\n",
    "- Created File with and without Post Season Performance\n",
    "- Set all missing values to 0\n",
    "\n",
    "![Alt text](prntscrns/ptms.png)\n",
    "\n",
    "\n",
    "## awards_players\n",
    "\n",
    "(All this was changed via python)\n",
    "- Removed League ID\n",
    "- Fixed an incorrectly inputted value (Kim Perrot Sportmanship -> Kim Perrot Sportmanship Award)\n",
    "- Abbreviated the award names to a standard (Capitalized and First Letters Only)\n",
    "\n",
    "![Alt text](prntscrns/awrds.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# teams_post data exploration and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEAMS POST\n",
    "# remove Lg ID\n",
    "# check for missing values and abnormal data\n",
    "\n",
    "teams_post = pd.read_csv(\"dataset/teams_post.csv\")\n",
    "teams_post.drop(columns=['lgID'], inplace=True)\n",
    "\n",
    "missing_values = teams_post.isna().sum().sum()\n",
    "print(f\"Missing values: {missing_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in teams_post.columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(range(len(teams_post)), teams_post[column], marker='.', label=column)\n",
    "    plt.title(f'{column} Data Distribution')\n",
    "    plt.ylabel(column)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_post.to_csv('dataset_edited/teams_post.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# coaches data exploration and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coaches\n",
    "# remove Lg ID\n",
    "# check for missing values and abnormal data\n",
    "# crate win/loss ratios\n",
    "\n",
    "coaches = pd.read_csv(\"dataset/coaches.csv\")\n",
    "coaches.drop(columns=['lgID'], inplace=True)\n",
    "\n",
    "#remove post data\n",
    "coaches.drop(columns=['post_wins', 'post_losses'], inplace=True)\n",
    "\n",
    "missing_values = teams_post.isna().sum().sum()\n",
    "print(f\"Missing values: {missing_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in coaches.columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(range(len(coaches)), coaches[column], marker='.', label=column)\n",
    "    plt.title(f'{column} Data Distribution')\n",
    "    plt.ylabel(column)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create w/l and post w/l ratio\n",
    "\n",
    "coaches['W/L Ratio'] = coaches['won'] / (coaches['lost'].replace(0, 1))\n",
    "#coaches['Post W/L Ratio'] = coaches['post_wins'] / (coaches['post_losses'].replace(0, 1))\n",
    "\n",
    "coaches.to_csv('dataset_edited/coaches.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Players Data Exploration and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Players\n",
    "# remove first and last season\n",
    "# ignore dead players\n",
    "# check for missing values and abnormal values\n",
    "\n",
    "players = pd.read_csv(\"dataset/players.csv\")\n",
    "players.drop(columns=['firstseason', 'lastseason'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to ignore for missing value check\n",
    "columns_to_ignore = [\"college\", \"collegeOther\"]\n",
    "\n",
    "# Find rows with missing values in all columns except the specified ones\n",
    "missing_rows = players.dropna(subset=[col for col in players.columns if col not in columns_to_ignore])\n",
    "\n",
    "missing_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove dead player data\n",
    "players_filtered = missing_rows[players['deathDate'] == '0000-00-00']\n",
    "players_filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "players_filtered.drop(columns=['deathDate'], inplace=True)\n",
    "\n",
    "players_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_filtered = [col for col in players_filtered.columns if col not in columns_to_ignore]\n",
    "for column in columns_filtered:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(range(len(players_filtered)), players_filtered[column], marker='.', label=column)\n",
    "    plt.title(f'{column} Data Distribution')\n",
    "    plt.ylabel(column)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with birthdate 0000-00-00\n",
    "\n",
    "players = players_filtered\n",
    "players = players[players['birthDate'] != '0000-00-00']\n",
    "players.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove abnormal heights\n",
    "\n",
    "players = players[players['height'] >= 50]\n",
    "\n",
    "players.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove abnormal weight\n",
    "\n",
    "players = players[players['weight'] >= 50]\n",
    "\n",
    "players.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_filtered = [col for col in players.columns if col not in columns_to_ignore]\n",
    "for column in columns_filtered:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(range(len(players)), players[column], marker='.', label=column)\n",
    "    plt.title(f'{column} Data Distribution')\n",
    "    plt.ylabel(column)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players.to_csv(\"dataset_edited/players.csv\", index=False)\n",
    "players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_dataset = pd.read_csv(\"dataset/teams.csv\")\n",
    "\n",
    "def merge_column(row):\n",
    "    if pd.isna(row['firstRound']) and pd.isna(row['semis']) and pd.isna(row['finals']):\n",
    "        return 'label0'\n",
    "    elif row['firstRound'] == 'L' and pd.isna(row['semis']) and pd.isna(row['finals']):\n",
    "        return 'label1'\n",
    "    elif row['firstRound'] == 'W' and row['semis'] == 'L' and pd.isna(row['finals']):\n",
    "        return 'label2'\n",
    "    elif row['firstRound'] == 'W' and row['semis'] == 'W' and row['finals'] == 'L':\n",
    "        return 'label3'\n",
    "    elif row['firstRound'] == 'W' and row['semis'] == 'W' and row['finals'] == 'W':\n",
    "        return 'label4'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "    \n",
    "def merge_to_ratio(row):\n",
    "    return round(row['won'] / row['GP'], 3)\n",
    "\n",
    "def home_win_ratio(row):\n",
    "    return round(row['homeW']/(row['homeW'] + row['homeL']), 3)\n",
    "\n",
    "def away_win_ratio(row):\n",
    "    return round(row['awayW']/(row['awayW'] + row['awayL']), 3)\n",
    "\n",
    "teams_dataset.drop(['lgID', 'franchID', 'divID', 'seeded', 'name', 'tmORB', 'tmDRB', 'tmTRB', 'opptmORB', 'opptmTRB', 'opptmDRB', 'confL', 'confW', 'attend', 'arena'], axis = 1, inplace=True)\n",
    "teams_dataset.rename(columns={'rank' : 'seed'}, inplace=True)\n",
    "    \n",
    "column_data = teams_dataset.apply(merge_column, axis=1)\n",
    "teams_dataset.insert(4, 'results', column_data)\n",
    "teams_dataset.drop(['firstRound', 'semis', 'finals'], axis=1, inplace = True)\n",
    "\n",
    "column_data = teams_dataset.apply(merge_to_ratio, axis=1)\n",
    "teams_dataset.insert(37, 'win_ratio', column_data)\n",
    "teams_dataset.drop(['won', 'lost', 'GP'], axis=1, inplace=True)\n",
    "\n",
    "column_data = teams_dataset.apply(home_win_ratio, axis=1)\n",
    "teams_dataset.insert(38, 'homeW_ratio', column_data)\n",
    "teams_dataset.drop(['homeW', 'homeL'], axis=1, inplace=True)\n",
    "\n",
    "column_data = teams_dataset.apply(away_win_ratio, axis=1)\n",
    "teams_dataset.insert(39, 'awayW_ratio', column_data)\n",
    "teams_dataset.drop(['awayW', 'awayL'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "for column in teams_dataset.iloc[:, 6:30]:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(range(len(teams_dataset)), teams_dataset[column], marker='.', label=column)\n",
    "    plt.title(f'{column} Data Distribution')\n",
    "    plt.ylabel(column)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seriesPost_dataset = pd.read_csv('dataset/series_post.csv')\n",
    "seriesPost_dataset.drop(['lgIDWinner', 'lgIDLoser'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "\n",
    "teams_dataset.head()\n",
    "\n",
    "# Select specific columns for correlation\n",
    "selected_columns = ['o_fgm', 'o_fga', 'o_ftm', 'o_fta', 'o_3pm', 'o_3pa', 'o_oreb', 'o_dreb', 'o_reb', 'o_stl', 'o_to', 'o_blk']\n",
    "\n",
    "# Calculate the correlation between selected columns\n",
    "correlation_matrix = teams_dataset[selected_columns].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_dataset['o_fg%'] = round(teams_dataset['o_fgm'] / teams_dataset['o_fga'] * 100, 2)\n",
    "teams_dataset['o_ft%'] = round(teams_dataset['o_ftm'] / teams_dataset['o_fta'] * 100, 2)\n",
    "teams_dataset['o_3p%'] = round(teams_dataset['o_3pm'] / teams_dataset['o_3pa'] * 100, 2)\n",
    "\n",
    "teams_dataset['d_fg%'] = round(teams_dataset['d_fgm'] / teams_dataset['d_fga'] * 100, 2)\n",
    "teams_dataset['d_ft%'] = round(teams_dataset['d_ftm'] / teams_dataset['d_fta'] * 100, 2)\n",
    "teams_dataset['d_3p%'] = round(teams_dataset['d_3pm'] / teams_dataset['d_3pa'] * 100, 2)\n",
    "\n",
    "teams_dataset.drop(['o_fgm', 'o_ftm', 'o_3pm'], axis=1, inplace=True)\n",
    "\n",
    "teams_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
