{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Description\n",
    "\n",
    "## awards_players\n",
    "\n",
    "- playerId\n",
    "- award (should standardize and abreviate)\n",
    "- Lg ID (remove)\n",
    "- year\n",
    "\n",
    "## coaches\n",
    "\n",
    "- lgId (remove)\n",
    "- Stint (timeperiod coach was at the team) (use to convert years)\n",
    "- Post_wins e Post_loses (playoff wins, irrelevant, remove)\n",
    "  \n",
    "## players_teams\n",
    "\n",
    "- Stint (timeperiod player was in the team)\n",
    "- lgId (remove)\n",
    "- GP (games played)\n",
    "- GS (game started)\n",
    "- ORebounds (offensive rebounds)\n",
    "- DRebounds (defensive rebounds)\n",
    "- rebounds (total) (check sum of previous 2)\n",
    "- turnovers (negative stat)\n",
    "- PF (Personal Fouls)\n",
    "- Fg Attempted (field goals attempted)\n",
    "- Fg Made (maybe change to ratio)\n",
    "- Ft (free throws)\n",
    "- Dq (desqualify)\n",
    "- Post ... (maybe ignore)\n",
    "\n",
    "## Players\n",
    "\n",
    "- POS (postion, has missing value) (Center, Forward-Center, Guard, Forward-Guard) (check if multiple positions over time)\n",
    "- firstseason e lastseason (remove)\n",
    "- height (missing values) (check if same units)\n",
    "- college (some missing values, some none)\n",
    "- death date (ignore dead players)\n",
    "\n",
    "## series and teams post\n",
    "- ignore files, reffering to the season after playoffs qualification  \n",
    "\n",
    "## teams\n",
    "\n",
    "- TmId (team Id), Franch ID (Franchise Id) (maybe irrelevant, maybe not)\n",
    "- DivId (remove, all empty)\n",
    "- Rank (maybe seed)\n",
    "- Seeded (remove)\n",
    "- **Playoff** (N, Y) to predict next\n",
    "- first round, semis, finals (change to one column that has numbers that relate to when they got eliminated) (label0-no playoffs, label1-loss on first round, label2-loss on semis, label3-loss on finals, label4-no losses)\n",
    "- Name (already have ID, may not be necessary)\n",
    "- O_fgm (offensive field goals made)\n",
    "- O_fga (offensive field goals attempted)\n",
    "- Tm ORB, Tm DRB, Tm TRB ,Oppmt ORS, Oppmt DRB, Oppmt TRB (all 0, remove)\n",
    "- GP (all teams play all games, maybe remove column)\n",
    "- Win Loss -> create ratio\n",
    "- Conf W L (maybe irrelevent)\n",
    "- Attend (number of spectators, maybe irrelevant)\n",
    "- Arena (remove)\n",
    "\n",
    "\n",
    "# Developments\n",
    "\n",
    "![Alt text](prntscrns/ptms.png)\n",
    "\n",
    "\n",
    "![Alt text](prntscrns/awrds.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## players_teams data exploration and processing\n",
    "\n",
    "(All this was changed via python)\n",
    "- Got per games for main statistical categories (Points, Assists, Rebounds (Off and Def), Steals, Blocks, Turnovers, Personal Fouls)\n",
    "- Got percentages for main shots (Field Goals, Free Throws, Three Pointers)\n",
    "- Removed League ID\n",
    "- Created File with and without Post Season Performance\n",
    "- Set all missing values to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_rem = [col for col in df.columns if \"lgID\" in col or \"Post\" in col]\n",
    "df[\"mpg\"] = df[\"minutes\"] / df[\"GP\"]\n",
    "df[\"ppg\"] = df[\"points\"] / df[\"GP\"] \n",
    "df[\"apg\"] = df[\"assists\"] / df[\"GP\"] \n",
    "df[\"rpg\"] = df[\"rebounds\"] / df[\"GP\"] \n",
    "df[\"spg\"] = df[\"steals\"] / df[\"GP\"] \n",
    "df[\"bpg\"] = df[\"blocks\"] / df[\"GP\"] \n",
    "df[\"topg\"] = df[\"turnovers\"] / df[\"GP\"] \n",
    "df[\"pfpg\"] = df[\"PF\"] / df[\"GP\"]\n",
    "df[\"fg%\"] = df[\"fgMade\"] / df[\"fgAttempted\"] * 100 \n",
    "df[\"3p%\"] = df[\"threeMade\"] / df[\"threeAttempted\"] *100 \n",
    "df[\"ft%\"] = df[\"ftMade\"] / df[\"ftAttempted\"] * 100 \n",
    "df[\"orpg\"] = df[\"oRebounds\"] / df[\"GP\"] \n",
    "df[\"drpg\"] = df[\"dRebounds\"] / df[\"GP\"]\n",
    "df = df.drop(columns=columns_rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_teams = pd.read_csv(\"dataset_edited/players_teams_w_percentage\")\n",
    "\n",
    "for column in players_teams.columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(range(len(players_teams)), players_teams[column], marker='.', label=column)\n",
    "    plt.title(f'{column} Data Distribution')\n",
    "    plt.ylabel(column)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## awards_players data exploration and processing\n",
    "\n",
    "(All this was changed via python)\n",
    "- Removed League ID\n",
    "- Fixed an incorrectly inputted value (Kim Perrot Sportmanship -> Kim Perrot Sportmanship Award)\n",
    "- Abbreviated the award names to a standard (Capitalized and First Letters Only)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# teams_post data exploration and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEAMS POST\n",
    "# remove Lg ID\n",
    "# check for missing values and abnormal data\n",
    "\n",
    "teams_post = pd.read_csv(\"dataset/teams_post.csv\")\n",
    "teams_post.drop(columns=['lgID'], inplace=True)\n",
    "\n",
    "missing_values = teams_post.isna().sum().sum()\n",
    "print(f\"Missing values: {missing_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in teams_post.columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(range(len(teams_post)), teams_post[column], marker='.', label=column)\n",
    "    plt.title(f'{column} Data Distribution')\n",
    "    plt.ylabel(column)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_post.to_csv('dataset_edited/teams_post.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# coaches data exploration and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coaches\n",
    "# remove Lg ID\n",
    "# check for missing values and abnormal data\n",
    "# crate win/loss ratios\n",
    "\n",
    "coaches = pd.read_csv(\"dataset/coaches.csv\")\n",
    "coaches.drop(columns=['lgID'], inplace=True)\n",
    "\n",
    "#remove post data\n",
    "coaches.drop(columns=['post_wins', 'post_losses'], inplace=True)\n",
    "\n",
    "missing_values = teams_post.isna().sum().sum()\n",
    "print(f\"Missing values: {missing_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in coaches.columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(range(len(coaches)), coaches[column], marker='.', label=column)\n",
    "    plt.title(f'{column} Data Distribution')\n",
    "    plt.ylabel(column)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in coaches.columns:\n",
    "    if column not in ['coachID', 'tmID', 'lgID']:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        data = coaches[column]\n",
    "\n",
    "        # Create a box plot\n",
    "        plt.boxplot(data, vert=False)\n",
    "\n",
    "        # Calculate quartiles, median, minimum, and maximum\n",
    "        quartiles = data.quantile([0.25, 0.5, 0.75])\n",
    "        median = quartiles[0.5]\n",
    "        minimum = data.min()\n",
    "        maximum = data.max()\n",
    "\n",
    "        # Add quartiles, median, minimum, and maximum to the plot\n",
    "        plt.text(\n",
    "            quartiles[0.25],\n",
    "            1.1,\n",
    "            f'Q1: {quartiles[0.25]:.2f}',\n",
    "            va='center',\n",
    "            ha='center',\n",
    "        )\n",
    "        plt.text(\n",
    "            quartiles[0.75],\n",
    "            1.1,\n",
    "            f'Q3: {quartiles[0.75]:.2f}',\n",
    "            va='center',\n",
    "            ha='center',\n",
    "        )\n",
    "        plt.text(\n",
    "            median,\n",
    "            1.2,\n",
    "            f'Median: {median:.2f}',\n",
    "            va='center',\n",
    "            ha='center',\n",
    "        )\n",
    "        plt.text(\n",
    "            minimum,\n",
    "            0.9,\n",
    "            f'Min: {minimum:.2f}',\n",
    "            va='center',\n",
    "            ha='center',\n",
    "        )\n",
    "        plt.text(\n",
    "            maximum,\n",
    "            1.3,\n",
    "            f'Max: {maximum:.2f}',\n",
    "            va='center',\n",
    "            ha='center',\n",
    "        )\n",
    "\n",
    "        plt.title(f'Box Plot for {column}')\n",
    "        plt.yticks([])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = coaches.select_dtypes(include=['number'])\n",
    "\n",
    "correlation_matrix = numerical_columns.corr()\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create w/l and post w/l ratio\n",
    "\n",
    "coaches['W/L Ratio'] = coaches['won'] / (coaches['lost'].replace(0, 1))\n",
    "#coaches['Post W/L Ratio'] = coaches['post_wins'] / (coaches['post_losses'].replace(0, 1))\n",
    "\n",
    "coaches.to_csv('dataset_edited/coaches.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Players Data Exploration and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Players\n",
    "# remove first and last season\n",
    "# ignore dead players\n",
    "# check for missing values and abnormal values\n",
    "\n",
    "players = pd.read_csv(\"dataset/players.csv\")\n",
    "players.drop(columns=['firstseason', 'lastseason'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to ignore for missing value check\n",
    "columns_to_ignore = [\"college\", \"collegeOther\"]\n",
    "\n",
    "# Find rows with missing values in all columns except the specified ones\n",
    "missing_rows = players.dropna(subset=[col for col in players.columns if col not in columns_to_ignore])\n",
    "\n",
    "missing_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove dead player data\n",
    "players_filtered = missing_rows[players['deathDate'] == '0000-00-00']\n",
    "players_filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "players_filtered.drop(columns=['deathDate'], inplace=True)\n",
    "\n",
    "players_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_filtered = [col for col in players_filtered.columns if col not in columns_to_ignore]\n",
    "for column in columns_filtered:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(range(len(players_filtered)), players_filtered[column], marker='.', label=column)\n",
    "    plt.title(f'{column} Data Distribution')\n",
    "    plt.ylabel(column)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with birthdate 0000-00-00\n",
    "\n",
    "players = players_filtered\n",
    "players = players[players['birthDate'] != '0000-00-00']\n",
    "players.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# convert to number of years\n",
    "players['birthDate'] = pd.to_datetime(players['birthDate'])\n",
    "\n",
    "current_date = datetime.now()\n",
    "players['age'] = ((current_date - players['birthDate']).dt.days / 365.25).round(2)  # 365.25 accounts for leap years\n",
    "players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate BMI per position\n",
    "\n",
    "positions = ['C', 'C-F', 'F', 'F-C', 'F-G', 'G', 'G-F']\n",
    "\n",
    "bmi_df = players[(players['height'] > 0) & (players['height'] != 9) & (players['weight'] > 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bmi(height_in_inches, weight_in_pounds):\n",
    "    # Convert height from inches to meters and weight from pounds to kilograms\n",
    "    height_in_meters = height_in_inches * 0.0254\n",
    "    weight_in_kilograms = weight_in_pounds * 0.453592\n",
    "    \n",
    "    # Calculate BMI\n",
    "    if height_in_meters > 0:\n",
    "        bmi = weight_in_kilograms / (height_in_meters ** 2)\n",
    "        return bmi\n",
    "    else:\n",
    "        return np.nan  # Return NaN for invalid height values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmi_df['BMI'] = bmi_df.apply(lambda row: calculate_bmi(row['height'], row['weight']), axis=1)\n",
    "\n",
    "average_bmi_by_position = bmi_df.groupby('pos')['BMI'].mean()\n",
    "\n",
    "print(average_bmi_by_position)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with abnormal heights and weights\n",
    "def calculate_missing_values(row):\n",
    "    pos = row['pos']\n",
    "    avg_bmi = average_bmi_by_position.get(pos)\n",
    "    if pd.notna(row['height']) and (pd.isna(row['weight']) or row['weight']==0):\n",
    "        # Calculate missing weight\n",
    "        print('================ new row found ==============')\n",
    "        print(row)\n",
    "        row['weight'] = (avg_bmi / 703) * (row['height'] * row['height'])\n",
    "        print('========== dif ===========')\n",
    "        print(row)\n",
    "    elif pd.notna(row['weight']) and (pd.isna(row['height']) or row['height']==0):\n",
    "        # Calculate missing height\n",
    "        row['height'] = ((row['weight'] / avg_bmi) ** 0.5) * 100\n",
    "    return row\n",
    "\n",
    "players = players.apply(lambda row: calculate_missing_values(row), axis=1)\n",
    "\n",
    "players = players[players['height'] >= 50]\n",
    "\n",
    "players.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove abnormal weight\n",
    "\n",
    "players = players[players['weight'] >= 50]\n",
    "\n",
    "players.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_filtered = [col for col in players.columns if col not in columns_to_ignore]\n",
    "for column in columns_filtered:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(range(len(players)), players[column], marker='.', label=column)\n",
    "    plt.title(f'{column} Data Distribution')\n",
    "    plt.ylabel(column)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns_filtered:\n",
    "    if column not in ['bioID', 'college', 'collegeOther', 'birthDate', 'pos']:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        data = players[column]\n",
    "\n",
    "        # Create a box plot\n",
    "        plt.boxplot(data, vert=False)\n",
    "\n",
    "        # Calculate quartiles, median, minimum, and maximum\n",
    "        quartiles = data.quantile([0.25, 0.5, 0.75])\n",
    "        median = quartiles[0.5]\n",
    "        minimum = data.min()\n",
    "        maximum = data.max()\n",
    "\n",
    "        # Add quartiles, median, minimum, and maximum to the plot\n",
    "        plt.text(\n",
    "            quartiles[0.25],\n",
    "            1.1,\n",
    "            f'Q1: {quartiles[0.25]:.2f}',\n",
    "            va='center',\n",
    "            ha='center',\n",
    "        )\n",
    "        plt.text(\n",
    "            quartiles[0.75],\n",
    "            1.1,\n",
    "            f'Q3: {quartiles[0.75]:.2f}',\n",
    "            va='center',\n",
    "            ha='center',\n",
    "        )\n",
    "        plt.text(\n",
    "            median,\n",
    "            1.2,\n",
    "            f'Median: {median:.2f}',\n",
    "            va='center',\n",
    "            ha='center',\n",
    "        )\n",
    "        plt.text(\n",
    "            minimum,\n",
    "            0.9,\n",
    "            f'Min: {minimum:.2f}',\n",
    "            va='center',\n",
    "            ha='center',\n",
    "        )\n",
    "        plt.text(\n",
    "            maximum,\n",
    "            1.3,\n",
    "            f'Max: {maximum:.2f}',\n",
    "            va='center',\n",
    "            ha='center',\n",
    "        )\n",
    "\n",
    "        plt.title(f'Box Plot for {column}')\n",
    "        plt.yticks([])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = players.select_dtypes(include=['number'])\n",
    "\n",
    "correlation_matrix = numerical_columns.corr()\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players.to_csv(\"dataset_edited/players.csv\", index=False)\n",
    "players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_dataset = pd.read_csv(\"dataset/teams.csv\")\n",
    "\n",
    "def merge_column(row):\n",
    "    if pd.isna(row['firstRound']) and pd.isna(row['semis']) and pd.isna(row['finals']):\n",
    "        return 'label0'\n",
    "    elif row['firstRound'] == 'L' and pd.isna(row['semis']) and pd.isna(row['finals']):\n",
    "        return 'label1'\n",
    "    elif row['firstRound'] == 'W' and row['semis'] == 'L' and pd.isna(row['finals']):\n",
    "        return 'label2'\n",
    "    elif row['firstRound'] == 'W' and row['semis'] == 'W' and row['finals'] == 'L':\n",
    "        return 'label3'\n",
    "    elif row['firstRound'] == 'W' and row['semis'] == 'W' and row['finals'] == 'W':\n",
    "        return 'label4'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "    \n",
    "def merge_to_ratio(row):\n",
    "    return round(row['won'] / row['GP'], 3)\n",
    "\n",
    "def home_win_ratio(row):\n",
    "    return round(row['homeW']/(row['homeW'] + row['homeL']), 3)\n",
    "\n",
    "def away_win_ratio(row):\n",
    "    return round(row['awayW']/(row['awayW'] + row['awayL']), 3)\n",
    "\n",
    "teams_dataset.drop(['lgID', 'franchID', 'divID', 'seeded', 'name', 'tmORB', 'tmDRB', 'tmTRB', 'opptmORB', 'opptmTRB', 'opptmDRB', 'confL', 'confW', 'attend', 'arena'], axis = 1, inplace=True)\n",
    "teams_dataset.rename(columns={'rank' : 'seed'}, inplace=True)\n",
    "    \n",
    "column_data = teams_dataset.apply(merge_column, axis=1)\n",
    "teams_dataset.insert(4, 'results', column_data)\n",
    "teams_dataset.drop(['firstRound', 'semis', 'finals'], axis=1, inplace = True)\n",
    "\n",
    "column_data = teams_dataset.apply(merge_to_ratio, axis=1)\n",
    "teams_dataset.insert(37, 'win_ratio', column_data)\n",
    "teams_dataset.drop(['won', 'lost', 'GP'], axis=1, inplace=True)\n",
    "\n",
    "column_data = teams_dataset.apply(home_win_ratio, axis=1)\n",
    "teams_dataset.insert(38, 'homeW_ratio', column_data)\n",
    "teams_dataset.drop(['homeW', 'homeL'], axis=1, inplace=True)\n",
    "\n",
    "column_data = teams_dataset.apply(away_win_ratio, axis=1)\n",
    "teams_dataset.insert(39, 'awayW_ratio', column_data)\n",
    "teams_dataset.drop(['awayW', 'awayL'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "for column in teams_dataset.iloc[:, 6:30]:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(range(len(teams_dataset)), teams_dataset[column], marker='.', label=column)\n",
    "    plt.title(f'{column} Data Distribution')\n",
    "    plt.ylabel(column)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seriesPost_dataset = pd.read_csv('dataset/series_post.csv')\n",
    "seriesPost_dataset.drop(['lgIDWinner', 'lgIDLoser'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "\n",
    "teams_dataset.head()\n",
    "\n",
    "# Select specific columns for correlation\n",
    "selected_columns = ['o_fgm', 'o_fga', 'o_ftm', 'o_fta', 'o_3pm', 'o_3pa', 'o_oreb', 'o_dreb', 'o_reb', 'o_stl', 'o_to', 'o_blk']\n",
    "\n",
    "# Calculate the correlation between selected columns\n",
    "correlation_matrix = teams_dataset[selected_columns].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_dataset['o_fg%'] = round(teams_dataset['o_fgm'] / teams_dataset['o_fga'] * 100, 2)\n",
    "teams_dataset['o_ft%'] = round(teams_dataset['o_ftm'] / teams_dataset['o_fta'] * 100, 2)\n",
    "teams_dataset['o_3p%'] = round(teams_dataset['o_3pm'] / teams_dataset['o_3pa'] * 100, 2)\n",
    "\n",
    "teams_dataset['d_fg%'] = round(teams_dataset['d_fgm'] / teams_dataset['d_fga'] * 100, 2)\n",
    "teams_dataset['d_ft%'] = round(teams_dataset['d_ftm'] / teams_dataset['d_fta'] * 100, 2)\n",
    "teams_dataset['d_3p%'] = round(teams_dataset['d_3pm'] / teams_dataset['d_3pa'] * 100, 2)\n",
    "\n",
    "teams_dataset.drop(['o_fgm', 'o_ftm', 'o_3pm'], axis=1, inplace=True)\n",
    "\n",
    "teams_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seriesPost_dataset.to_csv(\"dataset_edited/series_post.csv\", index=False)\n",
    "teams_dataset.to_csv(\"dataset_edited/teams.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
